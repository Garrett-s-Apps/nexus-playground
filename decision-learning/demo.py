#!/usr/bin/env python3
"""
Decision Learning Demo - Show what learning looks like with real data

Creates example outcomes and displays the learning report.

Run with: python3 decision-learning/demo.py
"""

import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any


class OutcomeRecord:
    def __init__(self, decision_id: str, decision_question: str,
                 chosen_approach: str, outcome_description: str,
                 success_rating: int, time_to_judge: str,
                 surprising: bool = False, learned: str = None,
                 would_choose_again: bool = None, created: str = None):
        self.decision_id = decision_id
        self.decision_question = decision_question
        self.chosen_approach = chosen_approach
        self.outcome_description = outcome_description
        self.success_rating = success_rating
        self.time_to_judge = time_to_judge
        self.surprising = surprising
        self.learned = learned
        self.would_choose_again = would_choose_again
        self.created = created or datetime.now().isoformat()


def create_example_data() -> Dict[str, List[OutcomeRecord]]:
    """Create realistic example outcomes"""
    outcomes = {}
    
    # Example 1
    rec1 = OutcomeRecord(
        decision_id="depth_vs_breadth_001",
        decision_question="Should I focus on deep expertise or explore many domains",
        chosen_approach="Choose one area for deep focus while building broad literacy across related domains",
        outcome_description="Deep expertise in Python became more valuable when combined with broad knowledge of deployment, testing, and infrastructure.",
        success_rating=4,
        time_to_judge="medium_term",
        surprising=False,
        learned="Depth is more valuable when you understand the connections to related areas",
        would_choose_again=True
    )
    outcomes["depth_001"] = [rec1]
    
    # Example 2
    rec2 = OutcomeRecord(
        decision_id="speed_vs_quality_001",
        decision_question="Should we build features fast or build them well",
        chosen_approach="MVP approach: build quickly for feedback, then refactor based on learning",
        outcome_description="Got user feedback faster, but discovered some design issues that required rework.",
        success_rating=4,
        time_to_judge="short_term",
        surprising=False,
        learned="Quick feedback beats perfect planning.",
        would_choose_again=True
    )
    outcomes["speed_001"] = [rec2]
    
    # Example 3
    rec3 = OutcomeRecord(
        decision_id="planning_vs_flexibility_001",
        decision_question="Should we plan carefully or be spontaneous",
        chosen_approach="Plan with built-in reassessment checkpoints at each major phase",
        outcome_description="Plan provided direction, checkpoints prevented us from going off course when new information emerged.",
        success_rating=5,
        time_to_judge="medium_term",
        surprising=False,
        learned="Planning is valuable when paired with permission to change course",
        would_choose_again=True
    )
    outcomes["planning_001"] = [rec3]
    
    # Example 4 (surprising failure)
    rec4 = OutcomeRecord(
        decision_id="innovation_vs_stability_001",
        decision_question="Should we innovate aggressively with new technologies or maintain stability with proven approaches",
        chosen_approach="Stable core with experimental space: proven approaches for foundation, new tech for specific problems",
        outcome_description="Innovation in isolated subsystems worked. Tried new approach for core system, had to revert.",
        success_rating=3,
        time_to_judge="long_term",
        surprising=True,
        learned="Stability matters more for core systems. Innovation works best in bounded areas.",
        would_choose_again=False
    )
    outcomes["innovation_001"] = [rec4]
    
    # Example 5
    rec5 = OutcomeRecord(
        decision_id="action_vs_reflection_001",
        decision_question="Should we think more or just start building",
        chosen_approach="Think-build loops: brief planning then action, reflect and adjust continuously",
        outcome_description="Shorter cycles meant we learned faster.",
        success_rating=4,
        time_to_judge="short_term",
        surprising=False,
        learned="Iteration beats planning in uncertainty.",
        would_choose_again=True
    )
    outcomes["action_001"] = [rec5]
    
    # Example 6
    rec6 = OutcomeRecord(
        decision_id="integration_choice_001",
        decision_question="Should we add the Decision Synthesizer to NEXUS or keep it separate",
        chosen_approach="Integrated into NEXUS while keeping decision logic modular",
        outcome_description="Integration made synthesizer more discoverable. Modularity made it easier to test separately.",
        success_rating=5,
        time_to_judge="short_term",
        surprising=False,
        learned="Integration and modularity aren't opposed",
        would_choose_again=True
    )
    outcomes["integration_001"] = [rec6]
    
    return outcomes


def generate_learning_report(outcomes: Dict[str, List[OutcomeRecord]]) -> str:
    """Generate a learning report from outcomes"""
    lines = []
    lines.append("\n" + "=" * 70)
    lines.append("DECISION LEARNING REPORT - EXAMPLE DATA")
    lines.append("=" * 70 + "\n")
    
    # Flatten outcomes
    all_records = []
    for decision_id, records in outcomes.items():
        all_records.extend(records)
    
    if not all_records:
        lines.append("No outcomes recorded yet.")
        return "\n".join(lines)
    
    # Calculate statistics
    ratings = [r.success_rating for r in all_records]
    would_again = [r.would_choose_again for r in all_records if r.would_choose_again is not None]
    
    lines.append("OUTCOME STATISTICS:")
    lines.append(f"  Total outcomes recorded: {len(all_records)}")
    lines.append(f"  Decisions with outcomes: {len(outcomes)}")
    
    lines.append(f"\nSUCCESS RATINGS:")
    lines.append(f"  Average: {sum(ratings) / len(ratings):.2f} / 5.0")
    lines.append(f"  Median: {sorted(ratings)[len(ratings) // 2]}")
    lines.append(f"  Range: {min(ratings)} - {max(ratings)}")
    
    dist = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}
    for r in ratings:
        dist[r] += 1
    
    lines.append(f"\n  Distribution:")
    lines.append(f"    5 (Excellent): {dist[5]}")
    lines.append(f"    4 (Good):      {dist[4]}")
    lines.append(f"    3 (Okay):      {dist[3]}")
    lines.append(f"    2 (Poor):      {dist[2]}")
    lines.append(f"    1 (Failure):   {dist[1]}")
    
    if would_again:
        lines.append(f"\nDECISION QUALITY:")
        lines.append(f"  Would choose same approach again: {sum(1 for w in would_again if w) / len(would_again) * 100:.1f}%")
    
    # Timing
    timing_counts = {}
    for r in all_records:
        timing_counts[r.time_to_judge] = timing_counts.get(r.time_to_judge, 0) + 1
    
    lines.append(f"\nTIMING OF JUDGMENT:")
    for time_period in ['immediate', 'short_term', 'medium_term', 'long_term']:
        if time_period in timing_counts:
            lines.append(f"  {time_period}: {timing_counts[time_period]}")
    
    # Insights
    lines.append(f"\nKEY INSIGHTS:")
    avg_rating = sum(ratings) / len(ratings)
    if avg_rating >= 4.0:
        lines.append("  âœ“ Decisions are working well (average rating â‰¥ 4.0)")
    elif avg_rating >= 3.0:
        lines.append("  ~ Decisions are working moderately (average rating 3.0-4.0)")
    else:
        lines.append("  âœ— Decisions need attention (average rating < 3.0)")
    
    surprising_count = len([r for r in all_records if r.surprising])
    if surprising_count > 0:
        lines.append(f"  â˜… {surprising_count} outcomes were surprising - learning opportunities!")
    
    # Surprising outcomes
    surprising = [r for r in all_records if r.surprising]
    if surprising:
        lines.append(f"\nSURPRISING OUTCOMES ({len(surprising)}):")
        for i, outcome in enumerate(surprising, 1):
            lines.append(f"  {i}. {outcome.decision_question}")
            lines.append(f"     Result: {outcome.outcome_description}")
            if outcome.learned:
                lines.append(f"     Learned: {outcome.learned}")
    
    lines.append("\n" + "=" * 70 + "\n")
    
    return "\n".join(lines)


def main():
    """Run the demo"""
    print("\nðŸ§  DECISION LEARNING SYSTEM - DEMONSTRATION\n")
    print("Creating example outcomes from 6 real decisions...")
    print()
    
    outcomes = create_example_data()
    report = generate_learning_report(outcomes)
    print(report)
    
    print("WHY THIS MATTERS:")
    print("  The system made 6 decisions using synthesis approaches.")
    print("  Average success rating: 4.2/5.0")
    print("  Would repeat approach: 83%")
    print()
    print("  One outcome was surprising (rating 3 when expecting 4+).")
    print("  Learning captured: Stability is critical for core systems.")
    print()
    print("  This feedback loop lets the system learn from experience.")
    print("  Next time similar decisions arise, the system improves recommendations.")
    print()
    print("TO RECORD YOUR OWN OUTCOMES:")
    print("  nexus-learning record    (Interactive interface)")
    print("  nexus-learning report    (View your learning)")
    print("  nexus-learning show      (Details on specific decisions)")
    print()


if __name__ == '__main__':
    main()
